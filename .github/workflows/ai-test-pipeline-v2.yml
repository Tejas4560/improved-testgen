name: AI Test Generation Pipeline V2

on:
  workflow_dispatch:
    inputs:
      repo_url:
        description: 'Target repository URL (leave empty to auto-detect)'
        required: false
        default: ''
        type: string
      repo_branch:
        description: 'Branch to test (leave empty to auto-detect)'
        required: false
        default: ''
        type: string
      min_coverage:
        description: 'Minimum coverage threshold (%)'
        required: false
        default: '90'
        type: string
      delta_threshold:
        description: 'Minimum coverage improvement required (pp)'
        required: false
        default: '0'
        type: string
      deploy_pages:
        description: 'Deploy coverage report to GitHub Pages'
        required: false
        default: 'true'
        type: string
      sonar_project_key:
        description: 'SonarQube Project Key (optional)'
        required: false
        default: ''
        type: string
      auto_push_tests:
        description: 'Auto-push generated tests to a dedicated branch'
        required: false
        default: 'false'
        type: string
      tests_branch:
        description: 'Branch name for generated tests (default: ai-generated-tests)'
        required: false
        default: 'ai-generated-tests'
        type: string

  workflow_call:
    inputs:
      repo_url:
        description: 'Target repository URL'
        required: false
        default: ''
        type: string
      repo_branch:
        description: 'Branch to test'
        required: false
        default: ''
        type: string
      min_coverage:
        description: 'Minimum coverage threshold (%)'
        required: false
        default: '90'
        type: string
      delta_threshold:
        description: 'Minimum coverage improvement required (pp)'
        required: false
        default: '0'
        type: string
      deploy_pages:
        description: 'Deploy coverage report to GitHub Pages'
        required: false
        default: 'true'
        type: string
      sonar_project_key:
        description: 'SonarQube Project Key'
        required: false
        default: ''
        type: string
      auto_push_tests:
        description: 'Auto-push generated tests to a dedicated branch'
        required: false
        default: 'false'
        type: string
      tests_branch:
        description: 'Branch name for generated tests'
        required: false
        default: 'ai-generated-tests'
        type: string

    secrets:
      AZURE_OPENAI_API_KEY:
        required: true
      AZURE_OPENAI_ENDPOINT:
        required: true
      AZURE_OPENAI_DEPLOYMENT:
        required: true
      AZURE_OPENAI_API_VERSION:
        required: false
      SONAR_HOST_URL:
        required: false
      SONAR_TOKEN:
        required: false
      GIT_PUSH_TOKEN:
        required: false

    outputs:
      coverage_before:
        description: 'Coverage before AI test generation'
        value: ${{ jobs.test-generation.outputs.coverage_before }}
      coverage_after:
        description: 'Coverage after AI test generation'
        value: ${{ jobs.test-generation.outputs.coverage_after }}
      coverage_delta:
        description: 'Coverage improvement (percentage points)'
        value: ${{ jobs.test-generation.outputs.coverage_delta }}
      tests_generated:
        description: 'Number of test files generated'
        value: ${{ jobs.test-generation.outputs.tests_generated }}
      tests_passed:
        description: 'Number of tests passed'
        value: ${{ jobs.test-generation.outputs.tests_passed }}
      tests_failed:
        description: 'Number of tests failed'
        value: ${{ jobs.test-generation.outputs.tests_failed }}
      pipeline_status:
        description: 'Pipeline status (success/failed)'
        value: ${{ jobs.test-generation.outputs.pipeline_status }}
      coverage_report_url:
        description: 'GitHub Pages URL for coverage report'
        value: ${{ jobs.test-generation.outputs.coverage_report_url }}
      threshold_passed:
        description: 'Whether coverage threshold was met'
        value: ${{ jobs.test-generation.outputs.threshold_passed }}
      delta_passed:
        description: 'Whether delta threshold was met'
        value: ${{ jobs.test-generation.outputs.delta_passed }}
      tests_branch_url:
        description: 'URL of the branch containing generated tests'
        value: ${{ jobs.test-generation.outputs.tests_branch_url }}

  pull_request:
    branches: [main, master]
    types: [opened, synchronize, reopened]

env:
  PYTHON_VERSION: '3.10'
  PIPELINE_REPO: 'Tejas4560/improved-testgen'
  PIPELINE_BRANCH: 'T1'
  GENERATION_TIMEOUT: '600'
  OPENAI_TIMEOUT: '120'
  OPENAI_REQUEST_TIMEOUT: '180'

jobs:
  test-generation:
    name: AI Test Generation
    runs-on: ubuntu-latest
    timeout-minutes: 60

    permissions:
      contents: write
      pages: write
      id-token: write
      pull-requests: write

    outputs:
      coverage_before: ${{ steps.metrics.outputs.coverage_before }}
      coverage_after: ${{ steps.metrics.outputs.coverage_after }}
      coverage_delta: ${{ steps.metrics.outputs.coverage_delta }}
      tests_generated: ${{ steps.metrics.outputs.tests_generated }}
      tests_passed: ${{ steps.metrics.outputs.tests_passed }}
      tests_failed: ${{ steps.metrics.outputs.tests_failed }}
      pipeline_status: ${{ steps.metrics.outputs.pipeline_status }}
      coverage_report_url: ${{ steps.deploy-pages.outputs.pages_url }}
      threshold_passed: ${{ steps.metrics.outputs.threshold_passed }}
      delta_passed: ${{ steps.metrics.outputs.delta_passed }}
      tests_branch_url: ${{ steps.push-tests.outputs.tests_branch_url }}

    steps:
      - name: Checkout Pipeline Repository
        uses: actions/checkout@v4
        with:
          repository: ${{ env.PIPELINE_REPO }}
          ref: ${{ env.PIPELINE_BRANCH }}
          path: pipeline

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Detect Target Repository
        id: detect-repo
        run: |
          echo "Detecting target repository..."

          REPO_URL="${{ inputs.repo_url }}"
          if [ -z "$REPO_URL" ]; then
            REPO_URL="https://github.com/${{ github.repository }}.git"
            echo "Auto-detected repo: $REPO_URL"
          fi

          REPO_BRANCH="${{ inputs.repo_branch }}"
          if [ -z "$REPO_BRANCH" ]; then
            if [ -n "${{ github.head_ref }}" ]; then
              REPO_BRANCH="${{ github.head_ref }}"
            elif [ -n "${{ github.ref_name }}" ]; then
              REPO_BRANCH="${{ github.ref_name }}"
            else
              REPO_BRANCH="main"
            fi
            echo "Auto-detected branch: $REPO_BRANCH"
          fi

          REPO_NAME=$(echo "$REPO_URL" | sed 's/.*\///' | sed 's/\.git$//')

          echo "repo_url=$REPO_URL" >> $GITHUB_OUTPUT
          echo "repo_branch=$REPO_BRANCH" >> $GITHUB_OUTPUT
          echo "repo_name=$REPO_NAME" >> $GITHUB_OUTPUT
          echo "Target: $REPO_NAME @ $REPO_BRANCH"

      - name: Clone Target Repository
        run: |
          echo "Cloning ${{ steps.detect-repo.outputs.repo_name }}..."
          cd ${{ github.workspace }}/pipeline
          # Full clone (not shallow) to match v1 behavior
          git clone --branch "${{ steps.detect-repo.outputs.repo_branch }}" "${{ steps.detect-repo.outputs.repo_url }}" target_repo
          echo "Target repository structure:"
          ls -la target_repo/
          PY_COUNT=$(find target_repo -name "*.py" -type f | wc -l)
          echo "Found $PY_COUNT Python files"

      - name: Install Pipeline Dependencies
        run: |
          cd ${{ github.workspace }}/pipeline
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          pip install pytest pytest-cov pytest-json-report coverage

      - name: Install Target Project Dependencies
        run: |
          cd ${{ github.workspace }}/pipeline
          source venv/bin/activate
          # Skip this step - let pipeline_runner.sh handle dependency installation
          # This avoids double-installation issues and ensures consistent behavior with v1
          echo "Skipping pre-installation (handled by pipeline_runner.sh)"
          if [ -f target_repo/requirements.txt ]; then
            echo "Target project has requirements.txt - will be installed by pipeline"
          fi

      - name: Measure Initial Coverage
        id: coverage-before
        run: |
          cd ${{ github.workspace }}/pipeline
          source venv/bin/activate
          echo "Measuring initial coverage (manual tests)..."

          COVERAGE_BEFORE="0"
          MANUAL_TESTS_FOUND="false"

          if find target_repo -name "test_*.py" -o -name "*_test.py" 2>/dev/null | head -1 | grep -q .; then
            MANUAL_TESTS_FOUND="true"
            echo "Found existing test files"
            cd target_repo
            PYTHONPATH=. python -m pytest --cov=. --cov-report=xml:coverage_before.xml --cov-report=term --ignore=venv --ignore=.venv -q 2>/dev/null || true
            if [ -f coverage_before.xml ]; then
              COVERAGE_BEFORE=$(python3 -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage_before.xml'); root = tree.getroot(); rate = float(root.attrib.get('line-rate', 0)); print(f'{rate * 100:.2f}')" 2>/dev/null || echo "0")
              cp coverage_before.xml ${{ github.workspace }}/pipeline/
            fi
            cd ..
          else
            echo "No existing tests found"
          fi

          echo "coverage_before=$COVERAGE_BEFORE" >> $GITHUB_OUTPUT
          echo "manual_tests_found=$MANUAL_TESTS_FOUND" >> $GITHUB_OUTPUT
          echo "Initial coverage: ${COVERAGE_BEFORE}%"

      - name: Run AI Test Generation Pipeline
        id: run-pipeline
        env:
          TARGET_ROOT: ${{ github.workspace }}/pipeline/target_repo
          PYTHONPATH: ${{ github.workspace }}/pipeline/target_repo
          MIN_COVERAGE_THRESHOLD: ${{ inputs.min_coverage || '90' }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT: ${{ secrets.AZURE_OPENAI_DEPLOYMENT }}
          AZURE_OPENAI_API_VERSION: ${{ secrets.AZURE_OPENAI_API_VERSION || '2024-02-15-preview' }}
          GENERATION_TIMEOUT: ${{ env.GENERATION_TIMEOUT }}
          OPENAI_TIMEOUT: ${{ env.OPENAI_TIMEOUT }}
          OPENAI_REQUEST_TIMEOUT: ${{ env.OPENAI_REQUEST_TIMEOUT }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_PROJECT_KEY: ${{ inputs.sonar_project_key }}
          GIT_PUSH_TOKEN: ${{ secrets.GIT_PUSH_TOKEN }}
        run: |
          cd ${{ github.workspace }}/pipeline
          source venv/bin/activate
          echo "Starting AI Test Generation Pipeline..."
          echo "   Target: ${{ steps.detect-repo.outputs.repo_name }}"
          echo "   Branch: ${{ steps.detect-repo.outputs.repo_branch }}"
          echo "   Min Coverage: ${{ inputs.min_coverage || '90' }}%"
          echo ""
          PIPELINE_EXIT_CODE=0
          bash ./pipeline_runner.sh || PIPELINE_EXIT_CODE=$?
          echo "pipeline_exit_code=$PIPELINE_EXIT_CODE" >> $GITHUB_OUTPUT
          if [ $PIPELINE_EXIT_CODE -eq 0 ]; then
            echo "Pipeline completed successfully"
          else
            echo "Pipeline completed with exit code: $PIPELINE_EXIT_CODE"
          fi

      - name: Extract Pipeline Metrics
        id: metrics
        if: always()
        run: |
          cd ${{ github.workspace }}/pipeline
          echo "Extracting pipeline metrics..."

          COVERAGE_BEFORE="${{ steps.coverage-before.outputs.coverage_before }}"
          [ -z "$COVERAGE_BEFORE" ] && COVERAGE_BEFORE="0"

          COVERAGE_AFTER="0"
          if [ -f coverage.xml ]; then
            COVERAGE_AFTER=$(python3 -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage.xml'); root = tree.getroot(); rate = float(root.attrib.get('line-rate', 0)); print(f'{rate * 100:.2f}')" 2>/dev/null || echo "0")
          fi

          COVERAGE_DELTA=$(python3 -c "before = float('$COVERAGE_BEFORE'); after = float('$COVERAGE_AFTER'); delta = after - before; print(f'{delta:+.2f}')" 2>/dev/null || echo "0")

          TESTS_GENERATED=0
          if [ -d tests/generated ]; then
            TESTS_GENERATED=$(find tests/generated -name "test_*.py" -type f | wc -l)
          fi

          TESTS_PASSED="0"
          TESTS_FAILED="0"
          TESTS_TOTAL="0"

          for json_file in .pytest_combined.json .pytest_generated.json .pytest_manual.json; do
            if [ -f "$json_file" ]; then
              TESTS_PASSED=$(python3 -c "import json; data = json.load(open('$json_file')); print(data.get('summary', {}).get('passed', 0))" 2>/dev/null || echo "0")
              TESTS_FAILED=$(python3 -c "import json; data = json.load(open('$json_file')); print(data.get('summary', {}).get('failed', 0))" 2>/dev/null || echo "0")
              TESTS_TOTAL=$(python3 -c "import json; data = json.load(open('$json_file')); print(data.get('summary', {}).get('total', 0))" 2>/dev/null || echo "0")
              break
            fi
          done

          MIN_COVERAGE="${{ inputs.min_coverage || '90' }}"
          DELTA_THRESHOLD="${{ inputs.delta_threshold || '0' }}"

          THRESHOLD_PASSED=$(python3 -c "print('true' if float('$COVERAGE_AFTER') >= float('$MIN_COVERAGE') else 'false')" 2>/dev/null || echo "false")
          DELTA_PASSED=$(python3 -c "delta = float('$COVERAGE_AFTER') - float('$COVERAGE_BEFORE'); print('true' if delta >= float('$DELTA_THRESHOLD') else 'false')" 2>/dev/null || echo "true")

          if [ "$THRESHOLD_PASSED" = "true" ]; then
            PIPELINE_STATUS="success"
          else
            PIPELINE_STATUS="threshold_not_met"
          fi

          echo "coverage_before=$COVERAGE_BEFORE" >> $GITHUB_OUTPUT
          echo "coverage_after=$COVERAGE_AFTER" >> $GITHUB_OUTPUT
          echo "coverage_delta=$COVERAGE_DELTA" >> $GITHUB_OUTPUT
          echo "tests_generated=$TESTS_GENERATED" >> $GITHUB_OUTPUT
          echo "tests_passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
          echo "tests_failed=$TESTS_FAILED" >> $GITHUB_OUTPUT
          echo "tests_total=$TESTS_TOTAL" >> $GITHUB_OUTPUT
          echo "threshold_passed=$THRESHOLD_PASSED" >> $GITHUB_OUTPUT
          echo "delta_passed=$DELTA_PASSED" >> $GITHUB_OUTPUT
          echo "pipeline_status=$PIPELINE_STATUS" >> $GITHUB_OUTPUT
          echo "manual_tests_found=${{ steps.coverage-before.outputs.manual_tests_found }}" >> $GITHUB_OUTPUT

          echo ""
          echo "========================================"
          echo "         PIPELINE METRICS              "
          echo "========================================"
          echo " Coverage Before (Manual):     ${COVERAGE_BEFORE}%"
          echo " Coverage After (AI + Manual): ${COVERAGE_AFTER}%"
          echo " Coverage Delta:               ${COVERAGE_DELTA} pp"
          echo "----------------------------------------"
          echo " Tests Generated:              ${TESTS_GENERATED} files"
          echo " Tests Passed:                 ${TESTS_PASSED}"
          echo " Tests Failed:                 ${TESTS_FAILED}"
          echo "----------------------------------------"
          THRESHOLD_STATUS="PASSED"
          DELTA_STATUS="PASSED"
          [ "$THRESHOLD_PASSED" != "true" ] && THRESHOLD_STATUS="FAILED"
          [ "$DELTA_PASSED" != "true" ] && DELTA_STATUS="FAILED"
          echo " Threshold (${MIN_COVERAGE}%):           $THRESHOLD_STATUS"
          echo " Delta Threshold (${DELTA_THRESHOLD} pp):      $DELTA_STATUS"
          echo "========================================"

      - name: Upload Test Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_number }}
          path: |
            ${{ github.workspace }}/pipeline/coverage.xml
            ${{ github.workspace }}/pipeline/coverage_before.xml
            ${{ github.workspace }}/pipeline/test-results.xml
            ${{ github.workspace }}/pipeline/.pytest_*.json
            ${{ github.workspace }}/pipeline/auto_fixer_report.json
            ${{ github.workspace }}/pipeline/coverage_gaps.json
            ${{ github.workspace }}/pipeline/manual_test_result.json
          if-no-files-found: warn
          retention-days: 30

      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ github.run_number }}
          path: |
            ${{ github.workspace }}/pipeline/htmlcov/
            ${{ github.workspace }}/pipeline/ast_full_analysis.json
            ${{ github.workspace }}/pipeline/ast_gap_analysis.json
          if-no-files-found: warn
          retention-days: 30

      - name: Upload Generated Tests
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: generated-tests-${{ github.run_number }}
          path: |
            ${{ github.workspace }}/pipeline/tests/generated/
          if-no-files-found: warn
          retention-days: 30

      - name: Push Generated Tests to Consumer Repository
        id: push-tests
        if: inputs.auto_push_tests == 'true' && steps.metrics.outputs.threshold_passed == 'true'
        env:
          GIT_PUSH_TOKEN: ${{ secrets.GIT_PUSH_TOKEN || secrets.GITHUB_TOKEN }}
        run: |
          cd ${{ github.workspace }}/pipeline

          # Check if there are generated tests
          if [ ! -d "tests/generated" ] || [ -z "$(ls -A tests/generated 2>/dev/null)" ]; then
            echo "No generated tests to push"
            echo "tests_pushed=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          GENERATED_COUNT=$(find tests/generated -name "test_*.py" -type f | wc -l)
          echo "Found $GENERATED_COUNT generated test files to push"

          # Get repository info
          REPO_URL="${{ steps.detect-repo.outputs.repo_url }}"
          SOURCE_BRANCH="${{ steps.detect-repo.outputs.repo_branch }}"
          TESTS_BRANCH="${{ inputs.tests_branch || 'ai-generated-tests' }}"

          # Convert HTTPS URL to authenticated URL
          # Handle both https://github.com/user/repo.git and https://github.com/user/repo formats
          AUTH_URL=$(echo "$REPO_URL" | sed "s|https://|https://x-access-token:${GIT_PUSH_TOKEN}@|")

          echo "Repository: $REPO_URL"
          echo "Source branch: $SOURCE_BRANCH"
          echo "Tests branch: $TESTS_BRANCH"

          # Configure git
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          # Clone consumer repo for pushing tests
          cd ${{ github.workspace }}
          rm -rf consumer-push-repo

          # Check if tests branch already exists
          if git ls-remote --heads "$REPO_URL" "$TESTS_BRANCH" | grep -q "$TESTS_BRANCH"; then
            echo "Tests branch '$TESTS_BRANCH' exists, will update it"
            git clone --branch "$TESTS_BRANCH" "$AUTH_URL" consumer-push-repo
            cd consumer-push-repo

            # Reset to source branch to ensure diff shows only generated tests
            git fetch origin "$SOURCE_BRANCH"
            git reset --hard "origin/$SOURCE_BRANCH"
          else
            echo "Tests branch '$TESTS_BRANCH' does not exist, will create it from '$SOURCE_BRANCH'"
            git clone --branch "$SOURCE_BRANCH" "$AUTH_URL" consumer-push-repo
            cd consumer-push-repo
            git checkout -b "$TESTS_BRANCH"
          fi

          # Create tests/generated directory and copy generated tests
          mkdir -p tests/generated
          cp -r ${{ github.workspace }}/pipeline/tests/generated/* tests/generated/

          # Check if there are changes
          git add tests/generated/

          if git diff --staged --quiet; then
            echo "No new changes to push"
            echo "tests_pushed=false" >> $GITHUB_OUTPUT
          else
            # Commit with simple message (coverage details in commit body via -m flags)
            git commit \
              -m "AI Generated Tests - Run #${{ github.run_number }}" \
              -m "Coverage: ${{ steps.metrics.outputs.coverage_after }}% | Tests: ${GENERATED_COUNT} files | Delta: ${{ steps.metrics.outputs.coverage_delta }} pp" \
              -m "Generated by AI Test Generation Pipeline" \
              -m "Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

            git push origin "$TESTS_BRANCH" --force

            echo "tests_pushed=true" >> $GITHUB_OUTPUT
            echo "Generated tests pushed to branch: $TESTS_BRANCH"
          fi

          # Generate branch URL for output
          # Convert git URL to browser URL
          BROWSER_URL=$(echo "$REPO_URL" | sed 's/\.git$//')
          BRANCH_URL="${BROWSER_URL}/tree/${TESTS_BRANCH}"
          COMPARE_URL="${BROWSER_URL}/compare/${SOURCE_BRANCH}...${TESTS_BRANCH}"

          echo "tests_branch_url=$BRANCH_URL" >> $GITHUB_OUTPUT
          echo "compare_url=$COMPARE_URL" >> $GITHUB_OUTPUT
          echo ""
          echo "========================================"
          echo "  Generated Tests Branch"
          echo "========================================"
          echo "  Branch: $TESTS_BRANCH"
          echo "  View:   $BRANCH_URL"
          echo "  Diff:   $COMPARE_URL"
          echo "========================================"

      - name: Deploy Coverage to GitHub Pages
        id: deploy-pages
        if: always()
        env:
          COV_BEFORE: ${{ steps.metrics.outputs.coverage_before }}
          COV_AFTER: ${{ steps.metrics.outputs.coverage_after }}
          COV_DELTA: ${{ steps.metrics.outputs.coverage_delta }}
          TESTS_GEN: ${{ steps.metrics.outputs.tests_generated }}
          TESTS_PASS: ${{ steps.metrics.outputs.tests_passed }}
          TESTS_FAIL: ${{ steps.metrics.outputs.tests_failed }}
          TESTS_TOTAL: ${{ steps.metrics.outputs.tests_total }}
          THRESHOLD_OK: ${{ steps.metrics.outputs.threshold_passed }}
          DELTA_OK: ${{ steps.metrics.outputs.delta_passed }}
          REPO_NAME: ${{ steps.detect-repo.outputs.repo_name }}
          BRANCH: ${{ steps.detect-repo.outputs.repo_branch }}
          RUN_NUM: ${{ github.run_number }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          MIN_COV: ${{ inputs.min_coverage || '90' }}
          DELTA_REQ: ${{ inputs.delta_threshold || '0' }}
        run: |
          cd ${{ github.workspace }}

          if [ ! -d "pipeline/htmlcov" ] || [ -z "$(ls -A pipeline/htmlcov 2>/dev/null)" ]; then
            echo "No coverage report to deploy"
            exit 0
          fi

          echo "Deploying coverage report to GitHub Pages..."
          export TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")

          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          git clone --depth=1 --branch gh-pages "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git" gh-pages-deploy 2>/dev/null || {
            echo "Creating new gh-pages branch..."
            mkdir gh-pages-deploy
            cd gh-pages-deploy
            git init
            git checkout -b gh-pages
            touch .nojekyll
            git add .
            git commit -m "Initialize gh-pages"
            cd ..
          }

          REPORT_DIR="coverage/run-${RUN_NUM}"
          mkdir -p "gh-pages-deploy/$REPORT_DIR/detail"

          # Copy raw htmlcov into detail/ subdirectory
          cp -r pipeline/htmlcov/* "gh-pages-deploy/$REPORT_DIR/detail/"

          # Generate dashboard and data.js using Python script
          python3 pipeline/src/generate_dashboard.py \
            pipeline/src/templates/dashboard.html \
            "gh-pages-deploy/$REPORT_DIR" \
            pipeline

          # Create root redirect to latest run
          cat > "gh-pages-deploy/index.html" << REDIRECT_EOF
          <!DOCTYPE html>
          <html>
          <head><meta http-equiv="refresh" content="0; url=coverage/run-${RUN_NUM}/index.html"></head>
          <body><p>Redirecting to <a href="coverage/run-${RUN_NUM}/index.html">latest report</a>...</p></body>
          </html>
          REDIRECT_EOF

          cd gh-pages-deploy
          touch .nojekyll
          git add -A

          if git diff --staged --quiet; then
            echo "No changes to deploy"
          else
            git commit -m "Deploy coverage report for run #${RUN_NUM}"
            git remote set-url origin "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git" 2>/dev/null || git remote add origin "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git"
            git push origin gh-pages --force
            echo "Coverage report deployed!"
          fi

          REPO_OWNER="${{ github.repository_owner }}"
          REPO_NAME_GH="${{ github.event.repository.name }}"
          PAGES_URL="https://${REPO_OWNER}.github.io/${REPO_NAME_GH}/coverage/run-${RUN_NUM}/index.html"

          echo "pages_url=$PAGES_URL" >> $GITHUB_OUTPUT
          echo "Coverage report: $PAGES_URL"

      - name: Generate Job Summary
        if: always()
        run: |
          # Collect all values
          REPO_NAME="${{ steps.detect-repo.outputs.repo_name }}"
          BRANCH="${{ steps.detect-repo.outputs.repo_branch }}"
          COV_BEFORE="${{ steps.metrics.outputs.coverage_before }}"
          COV_AFTER="${{ steps.metrics.outputs.coverage_after }}"
          COV_DELTA="${{ steps.metrics.outputs.coverage_delta }}"
          TESTS_GEN="${{ steps.metrics.outputs.tests_generated }}"
          TESTS_PASS="${{ steps.metrics.outputs.tests_passed }}"
          TESTS_FAIL="${{ steps.metrics.outputs.tests_failed }}"
          TESTS_TOTAL="${{ steps.metrics.outputs.tests_total }}"
          THRESHOLD_OK="${{ steps.metrics.outputs.threshold_passed }}"
          DELTA_OK="${{ steps.metrics.outputs.delta_passed }}"
          MANUAL_FOUND="${{ steps.metrics.outputs.manual_tests_found }}"
          MIN_COV="${{ inputs.min_coverage || '90' }}"
          DELTA_REQ="${{ inputs.delta_threshold || '0' }}"
          PAGES_URL="${{ steps.deploy-pages.outputs.pages_url }}"
          RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          # Determine overall status
          if [ "$THRESHOLD_OK" = "true" ] && [ "$DELTA_OK" = "true" ]; then
            STATUS_ICON="<picture><img alt='passed' src='https://img.shields.io/badge/Pipeline-PASSED-brightgreen?style=for-the-badge&logo=githubactions&logoColor=white' /></picture>"
            STATUS_TEXT="All quality gates passed"
          else
            STATUS_ICON="<picture><img alt='failed' src='https://img.shields.io/badge/Pipeline-THRESHOLD%20NOT%20MET-red?style=for-the-badge&logo=githubactions&logoColor=white' /></picture>"
            STATUS_TEXT="Coverage threshold not met"
          fi

          # Coverage progress bar (using Unicode block characters)
          COV_INT=$(python3 -c "print(int(float('$COV_AFTER')))" 2>/dev/null || echo "0")
          FILLED=$((COV_INT / 5))
          EMPTY=$((20 - FILLED))
          BAR=""
          for i in $(seq 1 $FILLED); do BAR="${BAR}█"; done
          for i in $(seq 1 $EMPTY); do BAR="${BAR}░"; done

          # Coverage color badge
          if [ "$COV_INT" -ge 90 ]; then
            COV_COLOR="brightgreen"
          elif [ "$COV_INT" -ge 70 ]; then
            COV_COLOR="yellow"
          elif [ "$COV_INT" -ge 50 ]; then
            COV_COLOR="orange"
          else
            COV_COLOR="red"
          fi

          # Pass rate
          PASS_RATE="0"
          if [ "$TESTS_TOTAL" != "0" ]; then
            PASS_RATE=$(python3 -c "print(f'{(int(\"$TESTS_PASS\") / int(\"$TESTS_TOTAL\")) * 100:.0f}')" 2>/dev/null || echo "0")
          fi

          # Write summary
          cat >> $GITHUB_STEP_SUMMARY << 'HEADER_EOF'
          <div align="center">

          # AI Test Generation Pipeline

          **Automated test generation powered by AI for maximum code coverage**

          HEADER_EOF

          echo "${STATUS_ICON}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "</div>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Repository details
          echo "### Repository" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> **${REPO_NAME}** on branch \`${BRANCH}\` | Run [#${{ github.run_number }}](${RUN_URL}) | Triggered by **${{ github.actor }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Coverage section
          echo "### Coverage Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "<table>" >> $GITHUB_STEP_SUMMARY
          echo "<tr>" >> $GITHUB_STEP_SUMMARY
          echo "<td width='50%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Final Coverage**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "${BAR} ${COV_AFTER}%" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| | Before | After | Change |" >> $GITHUB_STEP_SUMMARY
          echo "|---|--------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Line Coverage** | ${COV_BEFORE}% | **${COV_AFTER}%** | ${COV_DELTA} pp |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "<td width='50%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Quality Gates**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Threshold icons
          if [ "$THRESHOLD_OK" = "true" ]; then
            echo "| Check | Required | Actual | Result |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|----------|--------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| Coverage | >= ${MIN_COV}% | ${COV_AFTER}% | **PASSED** |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Check | Required | Actual | Result |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|----------|--------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| Coverage | >= ${MIN_COV}% | ${COV_AFTER}% | **FAILED** |" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$DELTA_OK" = "true" ]; then
            echo "| Delta | >= ${DELTA_REQ} pp | ${COV_DELTA} pp | **PASSED** |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Delta | >= ${DELTA_REQ} pp | ${COV_DELTA} pp | **FAILED** |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "</tr>" >> $GITHUB_STEP_SUMMARY
          echo "</table>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Test results
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "<table>" >> $GITHUB_STEP_SUMMARY
          echo "<tr>" >> $GITHUB_STEP_SUMMARY
          echo "<td align='center' width='25%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**${TESTS_GEN}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Files Generated" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "<td align='center' width='25%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**${TESTS_TOTAL}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Total Tests" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "<td align='center' width='25%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**${TESTS_PASS}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Passed" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "<td align='center' width='25%'>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**${TESTS_FAIL}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Failed" >> $GITHUB_STEP_SUMMARY
          echo "</td>" >> $GITHUB_STEP_SUMMARY
          echo "</tr>" >> $GITHUB_STEP_SUMMARY
          echo "</table>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "$TESTS_TOTAL" != "0" ]; then
            echo "> **Pass Rate: ${PASS_RATE}%** of test cases passed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Manual tests info
          if [ "$MANUAL_FOUND" = "true" ]; then
            echo "> Manual tests were detected and included in coverage measurement" >> $GITHUB_STEP_SUMMARY
          else
            echo "> No existing tests found — all tests were AI-generated" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # Generated Tests Branch section
          if [ "${{ inputs.auto_push_tests }}" = "true" ]; then
            echo "### Generated Tests" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            if [ "${{ steps.push-tests.outputs.tests_pushed }}" = "true" ]; then
              echo "> AI-generated tests have been pushed to branch \`${{ inputs.tests_branch || 'ai-generated-tests' }}\`" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "[View Branch](${{ steps.push-tests.outputs.tests_branch_url }}) | [Compare Changes](${{ steps.push-tests.outputs.compare_url }})" >> $GITHUB_STEP_SUMMARY
            elif [ "$THRESHOLD_OK" != "true" ]; then
              echo "> Tests were **not pushed** because coverage threshold was not met (${COV_AFTER}% < ${MIN_COV}%)" >> $GITHUB_STEP_SUMMARY
            else
              echo "> No new tests to push" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Links section
          echo "### Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Report | Link |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|------|" >> $GITHUB_STEP_SUMMARY
          if [ -n "$PAGES_URL" ]; then
            echo "| Coverage Report | [View Interactive Report](${PAGES_URL}) |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Test Artifacts | [Download](${RUN_URL}#artifacts) |" >> $GITHUB_STEP_SUMMARY
          echo "| Generated Tests | \`generated-tests-${{ github.run_number }}\` artifact |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Footer
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "<sub>Generated by **AI Test Generation Pipeline** | ${STATUS_TEXT}</sub>" >> $GITHUB_STEP_SUMMARY

      - name: Comment on Pull Request
        if: github.event_name == 'pull_request'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: ai-testgen-v2
          message: |
            <h2>AI Test Generation Pipeline</h2>

            <table>
            <tr>
            <td width="50%">

            **Coverage**

            | | Before | After | Delta |
            |---|:---:|:---:|:---:|
            | Line Coverage | ${{ steps.metrics.outputs.coverage_before }}% | **${{ steps.metrics.outputs.coverage_after }}%** | ${{ steps.metrics.outputs.coverage_delta }} pp |

            </td>
            <td width="50%">

            **Quality Gates**

            | Gate | Required | Actual | Status |
            |---|:---:|:---:|:---:|
            | Coverage | ${{ inputs.min_coverage || '90' }}% | ${{ steps.metrics.outputs.coverage_after }}% | ${{ steps.metrics.outputs.threshold_passed == 'true' && '**PASSED**' || '**FAILED**' }} |
            | Delta | ${{ inputs.delta_threshold || '0' }} pp | ${{ steps.metrics.outputs.coverage_delta }} pp | ${{ steps.metrics.outputs.delta_passed == 'true' && '**PASSED**' || '**FAILED**' }} |

            </td>
            </tr>
            </table>

            <details>
            <summary><strong>Test Details</strong> &mdash; ${{ steps.metrics.outputs.tests_generated }} files generated, ${{ steps.metrics.outputs.tests_passed }}/${{ steps.metrics.outputs.tests_total }} passed</summary>

            | Metric | Count |
            |--------|:-----:|
            | AI-Generated Test Files | ${{ steps.metrics.outputs.tests_generated }} |
            | Total Test Cases | ${{ steps.metrics.outputs.tests_total }} |
            | Passed | ${{ steps.metrics.outputs.tests_passed }} |
            | Failed | ${{ steps.metrics.outputs.tests_failed }} |

            </details>

            ${{ steps.deploy-pages.outputs.pages_url && format('[Coverage Report]({0})', steps.deploy-pages.outputs.pages_url) || '' }} | [Pipeline Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) ${{ inputs.auto_push_tests == 'true' && steps.push-tests.outputs.tests_pushed == 'true' && format('| [Generated Tests]({0})', steps.push-tests.outputs.tests_branch_url) || '' }}

            ---
            <sub>Run #${{ github.run_number }} | ${{ steps.metrics.outputs.threshold_passed == 'true' && steps.metrics.outputs.delta_passed == 'true' && 'All quality gates passed' || 'Quality gates not met' }} | AI Test Generation Pipeline</sub>

      - name: Check Thresholds
        if: always()
        run: |
          THRESHOLD_PASSED="${{ steps.metrics.outputs.threshold_passed }}"
          DELTA_PASSED="${{ steps.metrics.outputs.delta_passed }}"

          if [ "$THRESHOLD_PASSED" != "true" ]; then
            echo "Coverage threshold not met!"
            echo "   Required: ${{ inputs.min_coverage || '90' }}%"
            echo "   Actual:   ${{ steps.metrics.outputs.coverage_after }}%"
            exit 1
          fi

          if [ "$DELTA_PASSED" != "true" ]; then
            echo "Delta threshold not met!"
            echo "   Required: >= ${{ inputs.delta_threshold || '0' }} pp improvement"
            echo "   Actual:   ${{ steps.metrics.outputs.coverage_delta }} pp"
            exit 1
          fi

          echo "All thresholds passed!"
